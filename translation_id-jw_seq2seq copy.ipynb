{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import torchtext\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/gru_translation/bin/python\n",
      "Python 3.10.16\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.5\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, DatasetDict, concatenate_datasets\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(\"data/indonesia_jawa_dataset\").resolve()\n",
    "dataset = load_from_disk(str(dataset_path))  # Konversi ke string sebelum digunakan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: /Users/fathindifarobbani/Documents/Difa/UGM_S2 (MKA)/Semester 3/Pemrosesan Bahasa Alami Lanjut (PBAL)/Setelah UTS/Tugas2_Translation (2)/data/indonesia_jawa_dataset\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['indonesia', 'jawa'],\n",
      "        num_rows: 800\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['indonesia', 'jawa'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['indonesia', 'jawa'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import os\n",
    "\n",
    "dataset_path = os.path.abspath(\"data/indonesia_jawa_dataset\")\n",
    "print(f\"Loading dataset from: {dataset_path}\")\n",
    "\n",
    "dataset = load_from_disk(dataset_path)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (\n",
    "    dataset[\"train\"],\n",
    "    dataset[\"validation\"],\n",
    "    dataset[\"test\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indonesia': 'Mau bikin postingan yang isinya mengedukasi customers gojek.',\n",
       " 'jawa': 'Pengin nggawe postingan sing isine ngajari pelanggan Gojek.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 1392.55 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1350.66 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1360.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenisasi selesai dengan BERT tokenizer!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load tokenizer dari Hugging Face\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "def tokenize_example(example):\n",
    "    en_text = example[\"indonesia\"]  # Bahasa indonesia\n",
    "    id_text = example[\"jawa\"]  # Bahasa jawa\n",
    "\n",
    "    if lower:\n",
    "        en_text = en_text.lower()\n",
    "        id_text = id_text.lower()\n",
    "\n",
    "    # Tokenisasi menggunakan BERT tokenizer (subword tokenization)\n",
    "    en_tokens = [sos_token] + tokenizer.tokenize(en_text)[:max_length] + [eos_token]\n",
    "    id_tokens = [sos_token] + tokenizer.tokenize(id_text)[:max_length] + [eos_token]\n",
    "\n",
    "    # Jika token kosong, isi dengan <unk>\n",
    "    if len(en_tokens) <= 2:  # <sos> dan <eos> saja\n",
    "        en_tokens = [sos_token, \"<unk>\", eos_token]\n",
    "    if len(id_tokens) <= 2:\n",
    "        id_tokens = [sos_token, \"<unk>\", eos_token]\n",
    "\n",
    "    return {\n",
    "        \"en_tokens\": en_tokens,  # Token berbentuk string untuk bahasa Inggris\n",
    "        \"id_tokens\": id_tokens,  # Token berbentuk string untuk bahasa Indonesia\n",
    "    }\n",
    "\n",
    "# Parameter tokenisasi\n",
    "max_length = 1000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "# Pastikan train_data, valid_data, dan test_data dalam format Dataset dari Hugging Face\n",
    "train_data = train_data.map(lambda x: tokenize_example(x))\n",
    "valid_data = valid_data.map(lambda x: tokenize_example(x))\n",
    "test_data = test_data.map(lambda x: tokenize_example(x))\n",
    "\n",
    "print(\"✅ Tokenisasi selesai dengan BERT tokenizer!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buat Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1  # Turunkan dari 2 untuk memperluas vocabulary\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "# Gunakan token string dari train_data[\"en_tokens\"] dan train_data[\"id_tokens\"]\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    [example[\"en_tokens\"] for example in train_data],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "id_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    [example[\"id_tokens\"] for example in train_data],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "# Set default index untuk <unk>\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "en_vocab.set_default_index(unk_index)\n",
    "id_vocab.set_default_index(unk_index)\n",
    "\n",
    "assert en_vocab[unk_token] == id_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == id_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, id_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    id_ids = id_vocab.lookup_indices(example[\"id_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"id_ids\": id_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 2651.34 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1760.47 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 2028.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"id_vocab\": id_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"id_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (ID) Tokens: ['<sos>', 'ku', '##e', 'kas', '##eb', '##ut', 'dis', '##ugu', '##hak', '##e', 'supaya', 'aku', 'ng', '##eling', '-', 'eli', '##ng', '.', 'ka', '##be', '##h', 'khas', 'saka', 'ku', '##e', 'kuna', ',', 'saka', 'tampil', '##an', 'lan', 'rasa', '.', 'ku', '##e', 'kas', '##eb', '##ut', 'ena', '##k', 'lan', 're', '##gan', '##e', 'uga', 'mura', '##h', '.', '<eos>']\n",
      "Input (ID) Token IDs: tensor([   2,   26,   11,   19,   20,   21,  192,  476,  224,   11,  158,   18,\n",
      "          13,  910,   28, 1176,   78,    4,   73,  149,   22,  484,   49,   26,\n",
      "          11,  984,    5,   49,  136,   37,   10,   52,    4,   26,   11,   19,\n",
      "          20,   21,   45,    8,   10,   38,   97,   11,   41,  252,   22,    4,\n",
      "           3])\n",
      "Output (EN) Tokens: ['<sos>', 'ku', '##e', '-', 'ku', '##e', 'yang', 'disa', '##jikan', 'bi', '##kin', 'saya', 'bern', '##osta', '##lgi', '##a', '.', 'semua', '##nya', 'tipi', '##kal', 'ku', '##e', 'zaman', 'du', '##lu', ',', 'baik', 'dari', 'penampilan', 'maupun', 'rasa', '.', 'ku', '##eny', '##a', 'ena', '##k', 'dan', 'harga', '##nya', 'juga', 'mura', '##h', '.', '<eos>']\n",
      "Output (EN) Token IDs: tensor([   2,   63,   60,   21,   63,   60,    7,  202,  168,  121,  132,   11,\n",
      "        1348, 2323, 2221,   26,    4,  151,    6, 1930, 1573,   63,   60,  496,\n",
      "         391,  364,    5,  185,   46, 1861,  597,   34,    4,   63,  505,   26,\n",
      "          18,   10,    9,   40,    6,   32,  227,   15,    4,    3])\n",
      "Sample ID Token in Vocab: <sos>\n",
      "Sample EN Token in Vocab: <sos>\n"
     ]
    }
   ],
   "source": [
    "example = train_data[1]\n",
    "print(\"Input (ID) Tokens:\", example[\"id_tokens\"])\n",
    "print(\"Input (ID) Token IDs:\", example[\"id_ids\"])\n",
    "print(\"Output (EN) Tokens:\", example[\"en_tokens\"])\n",
    "print(\"Output (EN) Token IDs:\", example[\"en_ids\"])\n",
    "\n",
    "# Periksa token di vocabulary menggunakan lookup_token dan get_stoi\n",
    "sample_id_token_id = example[\"id_ids\"][0].item()\n",
    "sample_en_token_id = example[\"en_ids\"][0].item()\n",
    "\n",
    "sample_id_token = id_vocab.lookup_token(sample_id_token_id) if sample_id_token_id in id_vocab.get_stoi().values() else \"<unk>\"\n",
    "sample_en_token = en_vocab.lookup_token(sample_en_token_id) if sample_en_token_id in en_vocab.get_stoi().values() else \"<unk>\"\n",
    "\n",
    "print(\"Sample ID Token in Vocab:\", sample_id_token)\n",
    "print(\"Sample EN Token in Vocab:\", sample_en_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Token aku in ID Vocab:\", id_vocab.lookup_token(7) if 7 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token tau in ID Vocab:\", id_vocab.lookup_token(49) if 49 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token cara in ID Vocab:\", id_vocab.lookup_token(272) if 272 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token menggunakan in ID Vocab:\", id_vocab.lookup_token(451) if 451 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token ##nya in ID Vocab:\", id_vocab.lookup_token(13) if 13 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token ! in ID Vocab:\", id_vocab.lookup_token(16) if 16 in id_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token i in EN Vocab:\", en_vocab.lookup_token(8) if 8 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token know in EN Vocab:\", en_vocab.lookup_token(52) if 52 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token how in EN Vocab:\", en_vocab.lookup_token(71) if 71 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token to in EN Vocab:\", en_vocab.lookup_token(12) if 12 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token use in EN Vocab:\", en_vocab.lookup_token(315) if 315 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token this in EN Vocab:\", en_vocab.lookup_token(28) if 28 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token thing in EN Vocab:\", en_vocab.lookup_token(223) if 223 in en_vocab.get_stoi().values() else \"<unk>\")\n",
    "# print(\"Token ! in EN Vocab:\", en_vocab.lookup_token(17) if 17 in en_vocab.get_stoi().values() else \"<unk>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mengatur Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_id_ids = [example[\"id_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index) # menambah padding\n",
    "        batch_id_ids = nn.utils.rnn.pad_sequence(batch_id_ids, padding_value=pad_index) # menambah padding\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"id_ids\": batch_id_ids,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        outputs, hidden = self.rnn(embedded)  # no cell state in GRU!\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim + hidden_dim, hidden_dim)\n",
    "        self.fc_out = nn.Linear(embedding_dim + hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # n layers and n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        # context = [1, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        emb_con = torch.cat((embedded, context), dim=2)\n",
    "        # emb_con = [1, batch size, embedding dim + hidden dim]\n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        # output = [seq len, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [1, batch size, hidden dim]\n",
    "        output = torch.cat(\n",
    "            (embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim=1\n",
    "        )\n",
    "        # output = [batch size, embedding dim + hidden dim * 2]\n",
    "        prediction = self.fc_out(output)\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "        # context = [n layers * n directions, batch size, hidden dim]\n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [1, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(id_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 512 # dari 256\n",
    "decoder_embedding_dim = 512 # dari 256\n",
    "hidden_dim = 1024 # dari 512\n",
    "encoder_dropout = 0.3 # ubah jadi 0,6\n",
    "decoder_dropout = 0.3 # ubah jadi 0,6\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "# device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(2197, 512)\n",
       "    (rnn): GRU(512, 1024)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(2587, 512)\n",
       "    (rnn): GRU(1536, 1024)\n",
       "    (fc_out): Linear(in_features=2560, out_features=2587, bias=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 21,669,915 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       weight_decay=1e-5) # menambah ini utk regularisasi\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"id_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"id_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_epochs = 10\n",
    "# clip = 1.0\n",
    "# teacher_forcing_ratio = 0.5 # coba ubah dari 0.5\n",
    "\n",
    "# best_valid_loss = float(\"inf\")\n",
    "# patience = 5\n",
    "\n",
    "# for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "#     train_loss = train_fn(\n",
    "#         model,\n",
    "#         train_data_loader,\n",
    "#         optimizer,\n",
    "#         criterion,\n",
    "#         clip,\n",
    "#         teacher_forcing_ratio,\n",
    "#         device,\n",
    "#     )\n",
    "#     valid_loss = evaluate_fn(\n",
    "#         model,\n",
    "#         valid_data_loader,\n",
    "#         criterion,\n",
    "#         device,\n",
    "#     )\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), \"tut2-model.pt\")\n",
    "#         patience_counter = 0\n",
    "#     else:\n",
    "#         patience_counter += 1\n",
    "#         if patience_counter >= patience:\n",
    "#             print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "#             break\n",
    "#     print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "#     print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Teacher Forcing Ratio: 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:48<16:12, 108.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   7.551 | Train PPL: 1903.499\n",
      "\tValid Loss:   8.279 | Valid PPL: 3940.723\n",
      "Epoch 2/10 | Teacher Forcing Ratio: 0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:16<22:16, 167.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   7.892 | Train PPL: 2675.284\n",
      "\tValid Loss:   7.626 | Valid PPL: 2051.511\n",
      "Epoch 3/10 | Teacher Forcing Ratio: 0.411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [06:53<15:46, 135.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.836 | Train PPL: 930.663\n",
      "\tValid Loss:   7.003 | Valid PPL: 1100.355\n",
      "Epoch 4/10 | Teacher Forcing Ratio: 0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [09:20<13:59, 139.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.531 | Train PPL: 686.421\n",
      "\tValid Loss:   6.860 | Valid PPL: 953.433\n",
      "Epoch 5/10 | Teacher Forcing Ratio: 0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [12:45<13:36, 163.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.459 | Train PPL: 638.189\n",
      "\tValid Loss:   6.845 | Valid PPL: 939.495\n",
      "Epoch 6/10 | Teacher Forcing Ratio: 0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [13:31<08:13, 123.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.406 | Train PPL: 605.747\n",
      "\tValid Loss:   6.848 | Valid PPL: 941.911\n",
      "Epoch 7/10 | Teacher Forcing Ratio: 0.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [14:45<05:21, 107.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.368 | Train PPL: 583.051\n",
      "\tValid Loss:   6.865 | Valid PPL: 958.588\n",
      "Epoch 8/10 | Teacher Forcing Ratio: 0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [16:06<03:17, 98.92s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   6.348 | Train PPL: 571.271\n",
      "\tValid Loss:   6.876 | Valid PPL: 968.949\n",
      "Epoch 9/10 | Teacher Forcing Ratio: 0.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [17:16<04:19, 129.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Teacher Forcing Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteacher_forcing_ratio\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Panggil fungsi pelatihan dengan teacher_forcing_ratio yang diperbarui\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m valid_loss \u001b[38;5;241m=\u001b[39m evaluate_fn(\n\u001b[1;32m     38\u001b[0m     model,\n\u001b[1;32m     39\u001b[0m     valid_data_loader,\n\u001b[1;32m     40\u001b[0m     criterion,\n\u001b[1;32m     41\u001b[0m     device,\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Logika early stopping\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 20\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# trg = [(trg length - 1) * batch size]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "# Hyperparameter pelatihan\n",
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "initial_teacher_forcing_ratio = 0.5  # Nilai awal\n",
    "final_teacher_forcing_ratio = 0.1    # Nilai akhir\n",
    "best_valid_loss = float(\"inf\")\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "# Loop pelatihan dengan penurunan teacher_forcing_ratio\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    # Hitung teacher_forcing_ratio secara linier\n",
    "    teacher_forcing_ratio = initial_teacher_forcing_ratio - \\\n",
    "                            (initial_teacher_forcing_ratio - final_teacher_forcing_ratio) * (epoch / (n_epochs - 1))\n",
    "    \n",
    "    # Pastikan tidak kurang dari final_teacher_forcing_ratio\n",
    "    teacher_forcing_ratio = max(teacher_forcing_ratio, final_teacher_forcing_ratio)\n",
    "\n",
    "    # Cetak nilai teacher_forcing_ratio untuk debugging\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs} | Teacher Forcing Ratio: {teacher_forcing_ratio:.3f}\")\n",
    "\n",
    "    # Panggil fungsi pelatihan dengan teacher_forcing_ratio yang diperbarui\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    # Logika early stopping\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut2-model.pt\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "\n",
    "# Evaluasi setelah pelatihan\n",
    "model.load_state_dict(torch.load(\"tut2-model.pt\"))\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 6.644 | Test PPL: 767.833 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tut2-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"aku akan makan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terjemahan: . . . . . . . . . . . . . . . . . . . . . . . .\n"
     ]
    }
   ],
   "source": [
    "# sentence = \"Dia sangat pintar.\"\n",
    "translated = translate_sentence(sentence, model, tokenizer, en_vocab, id_vocab, \"<sos>\", \"<eos>\", device)\n",
    "print(\"Terjemahan:\", translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terjemahan: . .\n"
     ]
    }
   ],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    en_vocab,\n",
    "    id_vocab,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "    max_repetition=3  # Batas maksimum pengulangan token tidak bermakna\n",
    "):\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenisasi input\n",
    "    tokens = [sos_token] + tokenizer.tokenize(sentence.lower())[:1000] + [eos_token]\n",
    "    numericalized = [id_vocab[token] if token in id_vocab else id_vocab[\"<unk>\"] for token in tokens]\n",
    "    sentence_tensor = torch.LongTensor(numericalized).unsqueeze(1).to(device)\n",
    "\n",
    "    # Encoder\n",
    "    with torch.no_grad():\n",
    "        context = model.encoder(sentence_tensor)\n",
    "\n",
    "    # Decoder\n",
    "    trg_tokens = [en_vocab[sos_token]]\n",
    "    hidden = context\n",
    "    last_token = None\n",
    "    repeat_count = 0\n",
    "\n",
    "    for _ in range(max_output_length):\n",
    "        trg_tensor = torch.LongTensor([trg_tokens[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model.decoder(trg_tensor, hidden, context)\n",
    "        \n",
    "        # Ambil token dengan probabilitas tertinggi\n",
    "        top1 = output.argmax(1).item()\n",
    "        trg_tokens.append(top1)\n",
    "\n",
    "        # Cek pengulangan token tidak bermakna\n",
    "        current_token = en_vocab.lookup_token(top1)\n",
    "        if current_token in [\".\", \"<pad>\", \"<unk>\"]:  # Token yang dianggap tidak bermakna\n",
    "            if current_token == last_token:\n",
    "                repeat_count += 1\n",
    "            else:\n",
    "                repeat_count = 1\n",
    "            if repeat_count >= max_repetition:\n",
    "                break  # Hentikan jika pengulangan melebihi batas\n",
    "        else:\n",
    "            repeat_count = 0  # Reset jika token bermakna\n",
    "        \n",
    "        last_token = current_token\n",
    "\n",
    "        # Hentikan jika menemukan <eos>\n",
    "        if top1 == en_vocab[eos_token]:\n",
    "            break\n",
    "\n",
    "    # Konversi ke string\n",
    "    translated_tokens = en_vocab.lookup_tokens(trg_tokens[1:-1])  # Hapus <sos> & <eos>\n",
    "    translated_sentence = \" \".join(translated_tokens)\n",
    "    return translated_sentence\n",
    "\n",
    "# Contoh penggunaan\n",
    "sentence = \"aku akan makan\"\n",
    "translated = translate_sentence(sentence, model, tokenizer, en_vocab, id_vocab, \"<sos>\", \"<eos>\", device)\n",
    "print(\"Terjemahan:\", translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gru_translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
